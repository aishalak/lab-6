---
title: "Lab 6"
author: "Aisha Lakshman"
date: "2/24/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Packages
```{r}
library(tidyverse)
library(knitr)
library(broom)
library(leaps)
library(rms)
library(Sleuth3) #case1201 data
```

## Part I: Model Selection
```{r}
sat_scores <- Sleuth3::case1201 
full_model <- lm(SAT ~ Takers + Income + Years + Public + Expend + Rank , data = sat_scores)
tidy(full_model)
```
# Exercise 1
```{r}
select_summary$adjr2 #Extract adjusted rsq for models
coef(model_select, 1:6) #Display all possible models

model_select <- regsubsets(SAT ~ Takers + Income + Years + Public + Expend + 
                             Rank , data = sat_scores, method = "backward")
select_summary <- summary(model_select)
coef(model_select, id = 4) # Backward selection adjusted rsq
```
# Exercise 2
```{r}
select_summary$bic #Extract BIC for models
coef(model_select, 1:6) #Display all possible models

coef(model_select, id = 3) # Backward selection BIC
```
# Exercise 3
```{r}
model_select_aic <- step(full_model, direction = "backward")
tidy(model_select_aic, conf.int = TRUE) %>% 
  kable(format = "markdown", digits = 3)
```
# Exercise 4

The three backward selection models don't all have the same number of predictors. The adjusted R^2 model and the AIC model has 4 predictors, but the BIC model has 3 predictors. It is expected that the BIC model will have the fewest predictors because the penalty for BIC is larger than AIC if n is greater than or equal to 8.  




